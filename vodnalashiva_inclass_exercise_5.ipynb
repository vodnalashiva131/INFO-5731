{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vodnalashiva131/INFO-5731/blob/main/vodnalashiva_inclass_exercise_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "# **INFO5731 In-class Exercise 5**\n",
        "\n",
        "**This exercise aims to provide a comprehensive learning experience in text analysis and machine learning techniques, focusing on both text classification and clustering tasks.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU-pLW33lpcS"
      },
      "source": [
        "***Please use the text corpus you collected in your last in-class-exercise for this exercise. Perform the following tasks***.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission, and no requests will be answered. Manage your time accordingly.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "## **Question 1 (20 Points)**\n",
        "\n",
        "The purpose of the question is to practice different machine learning algorithms for **text classification** as well as the performance evaluation. In addition, you are requried to conduct **10 fold cross validation** (https://scikit-learn.org/stable/modules/cross_validation.html) in the training.\n",
        "\n",
        "\n",
        "\n",
        "The dataset can be download from canvas. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loi8Sh7UE6ha"
      },
      "source": [
        "**Algorithms:**\n",
        "\n",
        "*   MultinominalNB\n",
        "*   SVM\n",
        "*   KNN\n",
        "*   Decision tree\n",
        "*   Random Forest\n",
        "*   XGBoost\n",
        "*   Word2Vec\n",
        "*   BERT\n",
        "\n",
        "**Evaluation measurement:**\n",
        "\n",
        "\n",
        "*   Accuracy\n",
        "*   Recall\n",
        "*   Precison\n",
        "*   F-1 score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAZj4PHB70nf"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from gensim.models import Word2Vec\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kmx2jnHQ-BR0"
      },
      "outputs": [],
      "source": [
        "# load the data\n",
        "train_data = 'stsa-train.txt'\n",
        "test_data = 'stsa-test.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slAlbOgt-BR0"
      },
      "outputs": [],
      "source": [
        "def load_data(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.readlines()\n",
        "        data = []\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            sentiment, text = line.split(' ', 1)\n",
        "            data.append({'Emotion': sentiment, 'Text': text})\n",
        "        return pd.DataFrame(data)\n",
        "\n",
        "train_data = load_data(train_data)\n",
        "test_data = load_data(test_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bN0wmcGB-BR0",
        "outputId": "b153b591-ff6e-4a10-bc91-e80906d68347"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>a stirring , funny and finally transporting re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>apparently reassembled from the cutting-room f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>they presume their audience wo n't sit still f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>jonathan parker 's bartleby should have been t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Emotion                                               Text\n",
              "0       1  a stirring , funny and finally transporting re...\n",
              "1       0  apparently reassembled from the cutting-room f...\n",
              "2       0  they presume their audience wo n't sit still f...\n",
              "3       1  this is a visually stunning rumination on love...\n",
              "4       1  jonathan parker 's bartleby should have been t..."
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbITlbY2-BR1"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "X_train = train_data['Text']\n",
        "y_train = train_data['Emotion']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHW8sewY-BR1"
      },
      "outputs": [],
      "source": [
        "X_test = test_data['Text']\n",
        "y_test = test_data['Emotion']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOLpsUks-BR1"
      },
      "outputs": [],
      "source": [
        "# Split the Training Data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUtbMtT8-BR1"
      },
      "outputs": [],
      "source": [
        "# Vectorize the text data\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_val_vec = vectorizer.transform(X_val)\n",
        "X_test_vec = vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBU6hn28-BR1"
      },
      "outputs": [],
      "source": [
        "# Define Models\n",
        "models = {\n",
        "    \"MultinomialNB\": MultinomialNB(),\n",
        "    \"SVM\": SVC(),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"DecisionTree\": DecisionTreeClassifier(),\n",
        "    \"RandomForest\": RandomForestClassifier(),\n",
        "    \"XGBoost\": XGBClassifier()\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPpD4Oj6-BR2"
      },
      "outputs": [],
      "source": [
        "# perform 10 fold cross validation while trainig the classifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y\n",
        "                             _train, cv = 10)\n",
        "print(\"Accuracy: %f (%f)\" % (accuracies.mean(),\n",
        "                             accuracies.std()))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x629PdZm-BR2",
        "outputId": "039c2ede-cd73-42ab-f219-3a76c4a52460"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: MultinomialNB\n",
            "Cross Validation Scores: [0.76173285 0.8032491  0.78158845 0.80144404 0.7833935  0.75812274\n",
            " 0.78842676 0.78661844 0.7522604  0.78842676]\n",
            "Mean CV Score: 0.7805263054817504\n",
            "Model: SVM\n",
            "Cross Validation Scores: [0.72924188 0.72743682 0.71299639 0.72382671 0.74368231 0.7599278\n",
            " 0.75406872 0.72151899 0.72151899 0.75949367]\n",
            "Mean CV Score: 0.7353712275021055\n",
            "Model: KNN\n",
            "Cross Validation Scores: [0.58483755 0.56137184 0.58844765 0.57581227 0.5631769  0.55234657\n",
            " 0.60036166 0.56600362 0.54972875 0.54068716]\n",
            "Mean CV Score: 0.5682773973273447\n",
            "Model: DecisionTree\n",
            "Cross Validation Scores: [0.59927798 0.62454874 0.61552347 0.60830325 0.64981949 0.64620939\n",
            " 0.66546112 0.63652803 0.6039783  0.62206148]\n",
            "Mean CV Score: 0.6271711243561539\n",
            "Model: RandomForest\n",
            "Cross Validation Scores: [0.68231047 0.69314079 0.6967509  0.71119134 0.74187726 0.74187726\n",
            " 0.75045208 0.70705244 0.71971067 0.73417722]\n",
            "Mean CV Score: 0.7178540419503724\n",
            "Model: XGBoost\n",
            "Cross Validation Scores: [0.67870036 0.68772563 0.7166065  0.66967509 0.73465704 0.73104693\n",
            " 0.73056058 0.70524412 0.7124774  0.73417722]\n",
            "Mean CV Score: 0.710087086518563\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Cross Validation and Evaluation\n",
        "for name, model in models.items():\n",
        "    print(\"Model:\", name)\n",
        "    # Convert labels to integer type\n",
        "    y_train_int = y_train.astype(int)\n",
        "\n",
        "    # Cross Validation\n",
        "    cv_scores = cross_val_score(model, X_train_vec, y_train_int, cv=10)\n",
        "    print(\"Cross Validation Scores:\", cv_scores)\n",
        "    print(\"Mean CV Score:\", cv_scores.mean())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "## **Question 2 (20 Points)**\n",
        "\n",
        "The purpose of the question is to practice different machine learning algorithms for **text clustering**.\n",
        "\n",
        "Please downlad the dataset by using the following link.  https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\n",
        "(You can also use different text data which you want)\n",
        "\n",
        "**Apply the listed clustering methods to the dataset:**\n",
        "*   K-means\n",
        "*   DBSCAN\n",
        "*   Hierarchical clustering\n",
        "*   Word2Vec\n",
        "*   BERT\n",
        "\n",
        "You can refer to of the codes from  the follwing link below.\n",
        "https://www.kaggle.com/karthik3890/text-clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoQX5s4O70nf"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score\n",
        "from gensim.models import Word2Vec\n",
        "from sentence_transformers import SentenceTransformer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvNiW41c-BR2"
      },
      "outputs": [],
      "source": [
        "# Step 3: Feature Extraction\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# Initialize the CountVectorizer object\n",
        "vectorizer = CountVectorizer()\n",
        "# Fit and transform the training data\n",
        "X_train = vectorizer.fit_transform(train_data['Text'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dzxD5v9-BR2",
        "outputId": "8e25ca5b-d2b9-4fe6-ea88-cadb63be8e30"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=5, random_state=42)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KMeans(n_clusters=5, random_state=42)"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 4: Apply Clustering Algorithms\n",
        "# K-means\n",
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "kmeans.fit(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLnxP1rm-BR2",
        "outputId": "07d24772-68e0-4a20-c93d-29a3ad3e0502"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DBSCAN()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DBSCAN</label><div class=\"sk-toggleable__content\"><pre>DBSCAN()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "DBSCAN()"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# DBSCAN\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
        "dbscan.fit(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7AgbYnu-BR3"
      },
      "outputs": [],
      "source": [
        "# Hierarchical clustering\n",
        "hierarchical = AgglomerativeClustering(n_clusters=5)\n",
        "hierarchical.fit(X_train.toarray())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2JBRwIw-BR3"
      },
      "outputs": [],
      "source": [
        "# Word2Vec\n",
        "word2vec_model = Word2Vec(sentences=???)  # You need to provide sentences for training Word2Vec\n",
        "# Then you can use the word2vec_model for clustering\n",
        "\n",
        "# BERT\n",
        "bert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "X_bert = bert_model.encode(data['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRijW2aLGONl"
      },
      "source": [
        "**In one paragraph, please compare the results of K-means, DBSCAN, Hierarchical clustering, Word2Vec, and BERT.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIYCj5qyGfSL"
      },
      "source": [
        "**Write your response here:**\n",
        "\n",
        "In comparing the results of K-means, DBSCAN, Hierarchical clustering, Word2Vec, and BERT for text clustering, several observations can be made. K-means, being a centroid-based clustering algorithm, is sensitive to the choice of the number of clusters and tends to produce spherical clusters, which may not be ideal for text data with complex structures. DBSCAN, on the other hand, is a density-based algorithm that can discover clusters of arbitrary shapes and sizes, but its performance heavily depends on the choice of parameters such as epsilon and minimum samples. Hierarchical clustering provides a hierarchical structure of clusters, which can be advantageous for understanding relationships between clusters, but it may not scale well to large datasets. Word2Vec, a word embedding technique, captures semantic relationships between words but may struggle with out-of-vocabulary words and requires careful parameter tuning. BERT, a transformer-based language model, produces dense representations of text that capture context and semantic meaning effectively, but its computational cost and memory requirements may limit its applicability to large datasets. Overall, the choice of algorithm depends on the specific characteristics of the dataset and the desired outcome, balancing factors such as interpretability, scalability, and performance.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEs-OoDEhTW4"
      },
      "source": [
        "# Mandatory Question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUKC7suYhVl0"
      },
      "source": [
        "**Important: Reflective Feedback on this exercise**\n",
        "\n",
        "Please provide your thoughts and feedback on the exercises you completed in this assignment.\n",
        "\n",
        "\n",
        "**(Your submission will not be graded if this question is left unanswered)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAq0DZWAhU9m"
      },
      "outputs": [],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "Here's some reflective feedback on the exercises completed in this assignment:\n",
        "\n",
        "Answer:\n",
        "Text Classification Task: This exercise provided a good opportunity to practice implementing various machine learning algorithms for text classification, including data preprocessing, model selection, and evaluation. It was beneficial to work with different algorithms such as MultinomialNB, SVM, KNN, Decision Trees, Random Forest, and XGBoost, and to evaluate their performance using metrics like accuracy, precision, recall, and F1-score. The use of cross-validation helped in obtaining more robust performance estimates for the models.\n",
        "Text Clustering Task: This task allowed for exploring different clustering algorithms and feature extraction techniques for text data. However, the task could have been more specific regarding the evaluation of clustering results. While silhouette score and visual inspection were mentioned, a more thorough evaluation with clustering-specific metrics and techniques could have been included. Additionally, the Word2Vec and BERT sections lacked implementation details, making it difficult to fully understand how these techniques were applied for clustering.\n",
        "Overall, these exercises provided valuable hands-on experience in working with text data, applying machine learning algorithms, and evaluating model performance. However, providing more detailed instructions and examples, especially for advanced techniques like Word2Vec and BERT, would enhance the learning experience. Additionally, including more diverse datasets and real-world scenarios could further enrich the exercises and better prepare for practical applications in the field.\n",
        "\n",
        "'''"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}